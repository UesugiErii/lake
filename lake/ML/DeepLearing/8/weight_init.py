# 权重初始化
# weight initialize
# https://www.tensorflow.org/api_docs/python/tf/keras/initializers

##################################################################################
#                                                                                #
#  if you use relu as activation, then it is recommended to use VarianceScaling  #
#                                                                                #
##################################################################################

# class RandomNormal: Initializer that generates tensors with a normal distribution.

# class RandomUniform: Initializer that generates tensors with a uniform distribution.

# class TruncatedNormal: Initializer that generates a truncated normal distribution.

# class VarianceScaling: Initializer capable of adapting its scale to the shape of weights tensors.

# class glorot_normal: The Glorot normal initializer, also called Xavier normal initializer.

# class glorot_uniform: The Glorot uniform initializer, also called Xavier uniform initializer.

# class orthogonal: Initializer that generates an orthogonal matrix.

# class constant: Initializer that generates tensors with constant values.

# class zeros: Initializer that generates tensors initialized to 0.
